---
title: "R Notebook"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(smatr)
library(janitor)
library(skimr)
library(gridExtra)
library(olsrr)
library(purrr)
library(tidyr)

#source(here("R/func/min_cutoff.R"))
```


```{r, warning=FALSE}
biomass_data_taxaclean <- read_csv(here("data/processed/biomass_data_cleannames.csv"))
```

## setting minimum mass cut-off (due to higher proportional measurement error at very small mass values)

```{r}

  
tabyl(biomass_data_taxaclean$taxa_clean)
biomass_data_taxaclean_mass_cutoff <- biomass_data_taxaclean |>
    filter(wm_g >= 0.001, dm_g >=0.001, afdm_g >=0.001, wm_g >= dm_g, dm_g >= afdm_g) |>
  select(source, taxa_clean, preservation_method, wm_g, dm_g, afdm_g) |>
  print(n = Inf)
```

```{r}
min_cutoff(data = biomass_data_taxaclean, dm_g)

```

## filter frozen samples only

```{r}
biomass_frozen_taxaclean_mass_cutoff <- biomass_data_taxaclean_mass_cutoff |>
  filter(preservation_method == "Frozen")
```

## Create observation number

```{r}
biomass_wobs <- biomass_frozen_taxaclean_mass_cutoff |> 
  mutate(obs_num = row_number())
```

## Identifying outlier candidates

Creating Cleveland plots for each taxa as a visual tool to help identify observations that are far-removed from the rest.

```{r fig.height=15, fig.width=10}
biomass_wobs |> ggplot(aes(x = wm_g, y = obs_num, label = obs_num)) +
  facet_wrap(~ taxa_clean, ncol = 4, scale = "free") +
  geom_point(colour = "white") +
  geom_text()
```

Percentage analysis - identifying top and bottom 2.5% of the data for each mass variable

```{r}

biomass_frozen_percentiles <- biomass_wobs |>
  mutate(keep_data_wm_percentiles = ifelse(wm_g >= quantile(wm_g, 0.025, na.rm = TRUE) & wm_g <= quantile(wm_g, 0.975, na.rm = TRUE), TRUE, FALSE),
        keep_data_dm_percentiles = ifelse(dm_g >= quantile(dm_g, 0.025, na.rm = TRUE) & dm_g <= quantile(dm_g, 0.975, na.rm = TRUE), TRUE, FALSE))
  
# Which observations are identified by the percentile method
biomass_frozen_percentiles |> 
  ungroup() |> 
  filter(keep_data_wm_percentiles == FALSE) |> 
  select(taxa_clean, wm_g, keep_data_wm_percentiles, obs_num) |>
  print(n = Inf)
               
```

Here we are calculating measures of outlyingness and associated cutoff values for outlier identification

```{r}
#nesting by taxa
taxa_nested <- biomass_frozen_percentiles |> 
  select(taxa_clean, wm_g, dm_g) |> 
  nest(data = c(wm_g, dm_g))
  
# Chaining your maps
taxa_nested_outlier_measures <- taxa_nested |> 
  mutate(lm_object = map(.x = data,
                         ~ lm(dm_g ~ wm_g, data = .x)),
         n = map(.x = lm_object,
                 ~ nrow(.x$model)),
         predictors = map(.x = lm_object,
                          ~length(coef(.x))-1),
         leverage = map(.x = lm_object,
                        ~ hatvalues(.x)),
         leverage_cutoff = map2(.x = predictors,
                           .y = n,
                           ~ 2*(.x+1)/.y),
         stud_residual = map(.x = lm_object,
                             ~rstudent(.x)),
         alpha_tdist = map(.x = n,
                           ~0.05/.x),
         df_tdist = map2(.x = n,
                         .y = predictors,
                         ~.x-.y-1),
         critical_t = map2(.x = alpha_tdist,
                           .y = df_tdist,
                           ~qt(.x/2, .y, lower.tail = FALSE, log.p = FALSE)),
         cooks_d = map(.x = lm_object, 
                       ~ cooks.distance(.x)),
         cooks_d_cutoff = map2(.x = predictors,
                          .y = n,
                          ~qf(0.5, .x+1, .y-.x-1, lower.tail = FALSE)),
         dffits = map(.x = lm_object,
                      ~dffits(.x)),
         dffits_cutoff = map2(.x = n,
                              .y = predictors,
                              ~2*sqrt((.y+1)/.x)),
         dfbetas = map(.x = lm_object,
                       ~dfbetas(.x)),
         dfbetas_cutoff = map(.x = n,
                              ~2/sqrt(.x))
  )

```

## Introducing map2

```{r}
taxa_nested_outliers_identified <- taxa_nested_outlier_measures |>
  mutate(keep_data_leverage = map2(.x = leverage,
                         .y = leverage_cutoff,
                         ~.x < .y)) |>
  mutate(keep_data_stud_resid = map2(.x = stud_residual,
                                     .y = critical_t,
                                     ~.x < .y & .x > -.y)) |>
  mutate(keep_data_cook = map2(.x = cooks_d,
                          .y = cooks_d_cutoff,
                          ~.x < .y)) |>
  mutate(keep_data_dffits = map2(.x = dffits,
                                 .y = dffits_cutoff,
                                 ~.x < .y & .x > -.y)) |>
  mutate(keep_data_dfbetas = map2(.x = dfbetas,
                                  .y = dfbetas_cutoff,
                                  ~.x < .y & .x > -.y))


#Why does this return all zero's?
# taxa_lgl <- taxa_cook |> mutate(leverage_cutoff = map(.x = n,
#                                                      ~ 2*((length(coef(lm_object))-1)+1)/.x))
#taxa_lgl$leverage_cutoff
#but this works?
# taxa_lgl <- taxa_cook |> mutate(leverage_cutoff = map2(.x = lm_object,
#                                                       .y = n,
#                                                       ~ 2*((length(coef(.x))-1)+1)/.y))
# taxa_lgl$stud_residual


#Checking leverage value cutoff for Amphipoda
2*((length(coef(amphipoda_ols))-1)+1)/226

taxa_lgl |>
  select(leverage, stud_residual, cooks_d, dffits, dfbetas, keep_data_cook, keep_data_leverage, keep_data_stud_resid, keep_data_dffits, keep_data_dfbetas, taxa_clean)|>
  unnest(cols = c(leverage, stud_residual, cooks_d, dffits, dfbetas, keep_data_cook, keep_data_leverage, keep_data_stud_resid, keep_data_dffits, keep_data_dfbetas, taxa_clean)) |>
  filter(taxa_clean == "Amphipoda") |>
  select(dfbetas, keep_data_dfbetas) |>
  arrange(desc(dfbetas))|> print(n = Inf) |>
  tabyl(keep_data_dfbetas)
```


## Unnesting time

```{r}
# Check your rows pre and post nest
taxa_lgl |>
  select(data, keep_data_cook, keep_data_leverage, keep_data_stud_resid, keep_data_dffits, keep_data_dfbetas) |> 
  unnest(cols = c(data, keep_data_cook, keep_data_leverage, keep_data_stud_resid, keep_data_dffits, keep_data_dfbetas)) |> 
  nrow()

nrow(biomass_frozen_percentiles_removed)

taxa_unnested <- taxa_lgl |>
  select(data, keep_data_cook, keep_data_leverage, keep_data_stud_resid, keep_data_dffits, keep_data_dfbetas) |> 
  unnest(cols = c(data, keep_data_cook, keep_data_leverage, keep_data_stud_resid, keep_data_dffits, keep_data_dfbetas)) 

# checking separation of dfbetas values for intercept and slope
taxa_unnested$keep_data_dfbetas
keep_data_dfbetas_int <- taxa_unnested$keep_data_dfbetas[,1]
keep_data_dfbetas_slope <- taxa_unnested$keep_data_dfbetas[,2]
keep_data_dfbetas_int == keep_data_dfbetas_slope

# Filter out values based on thresholds of outlier measures
taxa_unnested <- taxa_unnested |>
  mutate(keep_data_dfbetas_int = keep_data_dfbetas[,1], 
         keep_data_dfbetas_slope = keep_data_dfbetas[,2]) |>
  mutate(keep_data_wm_percentiles = ifelse(wm_g >= quantile(wm_g, 0.025, na.rm = TRUE) & wm_g <= quantile(wm_g, 0.975, na.rm = TRUE), TRUE, FALSE),
        keep_data_dm_percentiles = ifelse(dm_g >= quantile(dm_g, 0.025, na.rm = TRUE) & dm_g <= quantile(dm_g, 0.975, na.rm = TRUE), TRUE, FALSE)) |>
  mutate(keep_data = ifelse(keep_data_wm_percentiles == TRUE & keep_data_dm_percentiles == TRUE & keep_data_cook == TRUE & keep_data_leverage == TRUE & keep_data_stud_resid == TRUE & keep_data_dffits == TRUE & keep_data_dfbetas_int == TRUE & keep_data_dfbetas_slope == TRUE, TRUE, FALSE)) 

taxa_unnested |> 
  pull(keep_data) |> 
  janitor::tabyl()

biomass_frozen_outliers_removed <- taxa_unnested |> 
  filter(keep_data == TRUE) |>
  select(taxa_clean, wm_g, dm_g)

biomass_frozen_outliers_removed


### A possible alternative but not as good as yours! because u can't check the remaining FALSEs
taxa_unnested |> 
  mutate(keep_data_dfbetas_int = keep_data_dfbetas[,1], 
         keep_data_dfbetas_slope = keep_data_dfbetas[,2]) |>
  mutate(keep_data_wm_percentiles = ifelse(wm_g >= quantile(wm_g, 0.025, na.rm = TRUE) & wm_g <= quantile(wm_g, 0.975, na.rm = TRUE), TRUE, FALSE),
         keep_data_dm_percentiles = ifelse(dm_g >= quantile(dm_g, 0.025, na.rm = TRUE) & dm_g <= quantile(dm_g, 0.975, na.rm = TRUE), TRUE, FALSE)) |>
  filter(keep_data_wm_percentiles == TRUE & keep_data_dm_percentiles == TRUE & keep_data_cook == TRUE & keep_data_leverage == TRUE & keep_data_stud_resid == TRUE & keep_data_dffits == TRUE & keep_data_dfbetas_int == TRUE & keep_data_dfbetas_slope == TRUE) 
```

### Get a summary table of counts for all outlier methods 
```{r}
# Get n for each taxa
taxa_lgl |>
  select(n) |> 
  unnest() |> 
  print(n = Inf)

# The NAs are ok!
taxa_unnested |> 
  ungroup() |> 
  filter(is.na(keep_data_cook))
  #colSums(na.rm = )

# Hacky
taxa_unnested |> 
  ungroup() |> 
  select(starts_with("keep")) |> 
  colSums(na.rm = TRUE) # Sums all the TRUES in each column

# Wrangling way
long_data <- taxa_unnested |> 
  ungroup() |> 
  select(-c(keep_data_dfbetas)) |> 
  pivot_longer(starts_with("keep"), names_to = "outlier_method") 

# Summary of counts
long_data |> 
  group_by(outlier_method) |> 
  summarise(n = n(),
            n_FALSE = length(which(value == FALSE)),
            n_TRUE = length(which(value == TRUE)),
            n_NA = length(which(is.na(value))),
            n_add_check = n_FALSE + n_TRUE + n_NA
  )

# Treating as numeric TRUE becomes 1 FALSE becomes 0
# Then we spcify condition == 0 means identifying the false ones
# Wrapping which around the identified values, tells us the index/observation number of the ones we've identified
long_data$value
as.numeric(long_data$value)
as.numeric(long_data$value) == 0

which(as.numeric(long_data$value) == 0)

length(long_data$value)

length(which(as.numeric(long_data$value) == 0))
```


# Save the cleaned data

```{r}
write_csv(biomass_frozen_outliers_removed, here("data/processed/biomass_conversions_frozen_nooutliers.csv"))
```

